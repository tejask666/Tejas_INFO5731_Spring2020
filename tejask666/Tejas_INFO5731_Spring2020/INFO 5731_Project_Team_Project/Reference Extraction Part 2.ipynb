{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled25.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoqeiSBCKrV140++aWTDT1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejask666/Tejas_INFO5731_Spring2020/blob/master/tejask666/Tejas_INFO5731_Spring2020/INFO%205731_Project_Team_Project/Reference%20Extraction%20Part%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d29-se9EBm9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARU7q3OyBvWF",
        "colab_type": "text"
      },
      "source": [
        "# **INFO 5731 COMPUTATIONAL METHODS FOR INFORMATION SYSTEMS**\n",
        "\n",
        "**This project aims to gather all references from scientific articles that will improve the credibility of the services offered by behavior analysts**\n",
        "\n",
        "**Extracting References**\n",
        "\n",
        "5.Journal of Applied Behavior Analysis \n",
        "\n",
        "6.Journal of the Experimental Analysis of Behavior\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6RdoSM9CZ2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "import os\n",
        "import re,datetime\n",
        "import time\n",
        "import csv\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from google.colab import files\n",
        "from selenium import webdriver\n",
        "  \n",
        "class In_Class_Assigment():\n",
        "    def get_data(self,list_of_journal):\n",
        "        list_of_data=[]\n",
        "        print(list_of_journal)\n",
        "        # Launch chrome browser.\n",
        "        obj = In_Class_Assigment()\n",
        "        options = webdriver.ChromeOptions()\n",
        "        # Runs browser in background.\n",
        "        options.add_argument('--headless')\n",
        "        options.add_argument('--no-sandbox')\n",
        "        options.add_argument('--disable-dev-shm-usage')\n",
        "        options.add_argument('--disable-gpu')\n",
        "        options.add_argument(\"--window-size=1920,1080\")\n",
        "        options.add_argument(\"start-maximized\")\n",
        "        options.add_argument(\"disable-infobars\")  \n",
        "        options.add_argument(\"--disable-extensions\")\n",
        "        driver = webdriver.Chrome('chromedriver',options=options)\n",
        "        driver.maximize_window()\n",
        "        #This loop will run twice as there are two journals.\n",
        "        for journal in range(len(list_of_journal)):\n",
        "            with open(r'/content/Book1.csv', 'a', newline='') as file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow([list_of_journal[journal][3]])\n",
        "            list_of_data = list_of_journal[journal]\n",
        "         #driver.get is use to access url.\n",
        "            driver.get(list_of_data[2])\n",
        "            driver.find_element_by_xpath(\"//input[@name='user']\").send_keys(\"tpk0023\")\n",
        "            driver.find_element_by_xpath(\"//input[@name='pass']\").send_keys(\"Jan@022019\")\n",
        "          # finds year,but before that it checks it is already expanded or not.   \n",
        "            driver.find_element_by_xpath(\"//input[@type='submit']\").click()\n",
        "            time.sleep(2)\n",
        "            expand_years = driver.find_elements_by_xpath(\"//i[@class='icon-add_box']//following::span[1]\")\n",
        "            for expand in range(len(expand_years)):  # count\n",
        "                print(\"*************in expand years*************\")\n",
        "                expand_years = driver.find_elements_by_xpath(\"//i[@class='icon-add_box']//following::span[1]\")\n",
        "                expand_years[expand].click()\n",
        "                year_range = expand_years[expand].text\n",
        "                y = year_range.split(\" - \")\n",
        "                year_range = y[0] + \"-\" + y[1]\n",
        "                sublist= \"//ul[@id='#value']//li\"\n",
        "                sublist=sublist.replace('#value',year_range)\n",
        "                print(sublist)\n",
        "                sub_list=driver.find_elements_by_xpath(sublist)\n",
        "                for i in range(len(sub_list)):\n",
        "                    print(\"***************in sublist***********\")\n",
        "                    sub_list = driver.find_elements_by_xpath(sublist)\n",
        "                    sub_list[i].click()\n",
        "                    time.sleep(5)\n",
        "                    issue_list= driver.find_elements_by_xpath(\"(//a[contains(text(),'Volume')])\")\n",
        "                    for issue in range(len(issue_list)):#\n",
        "                        print(\"************in issue list**********\")\n",
        "             #This finds webelement i.e.location of references  \n",
        "                        issue_list = driver.find_elements_by_xpath(\"(//a[contains(text(),'Volume')])\")\n",
        "                        issue_list[issue].click()\n",
        "                        time.sleep(18)\n",
        "                        ref_list=driver.find_elements_by_xpath(\"//a[@title='References']\")\n",
        "             # This loop will run for the number pages i.e. on which articles are available.            \n",
        "                        for ref in range(len(ref_list)):#\n",
        "                            time.sleep(30)\n",
        "                            print(\"************in reflist****************\")\n",
        "                            ref_list = driver.find_elements_by_xpath(\"//a[@title='References']\")\n",
        "                            ref_list[ref].click()\n",
        "                            time.sleep(15)\n",
        "                            try:\n",
        "                                ref_tab=driver.find_elements_by_xpath(\"(//span[text()='REFERENCES'])[2]\")\n",
        "                                if len(ref_tab)>0:\n",
        "              #driver.execute_script(\"arguments[0].scrollIntoView();\",ref_tab)\n",
        "                                    ref_tab[0].click()\n",
        "                                    actual_ref = driver.find_elements_by_xpath(\"//div[@class='accordion__content']//ul//li\")\n",
        "                                    if actual_ref != []:\n",
        "                                        for r in range (1,len(actual_ref)):#1,\n",
        "                                            print(\"in references tab\")\n",
        "                                            actual_ref = driver.find_elements_by_xpath(\"//div[@class='accordion__content']//ul//li\")\n",
        "                                            if len(actual_ref) !=[]:\n",
        "                                               reference_text= actual_ref[r].text\n",
        "             # Actual content i.e. data which we want to extract from webpage is saved in reference_text in \n",
        "                                               author=obj.get_author(reference_text)\n",
        "                                               if author != None:\n",
        "                                                  author.append(list_of_data[3])\n",
        "                                                  obj.writeintocsv(author)\n",
        "                                               else:\n",
        "                                                  continue\n",
        "                                    #driver.back()\n",
        "                                        print(\"returned\")\n",
        "                                        driver.back()\n",
        "                                else:\n",
        "                                  driver.back()\n",
        "                                  continue        \n",
        "                            except NoSuchElementException:\n",
        "                                citing=driver.find_elements_by_xpath(\"//span[text()='Citing Literature']\")\n",
        "                                if len(citing)>0:\n",
        "                                  citing[0].click()\n",
        "                                  time.sleep(3)\n",
        "                                  actual_ref = driver.find_elements_by_xpath(\"//li[@class='citedByEntry']\")\n",
        "                                  if actual_ref != []:\n",
        "                                    for r in range(1,len(actual_ref)):#\n",
        "                                        print(\"******************in citing literatur*************\")\n",
        "                                        actual_ref = driver.find_elements_by_xpath(\"//li[@class='citedByEntry']\")\n",
        "                                        reference_text = actual_ref[r].text\n",
        "                                        author = obj.get_author(reference_text)\n",
        "                                        if author != None:\n",
        "                                           author.append(list_of_data[3])\n",
        "                                           obj.writeintocsv(author)\n",
        "                                        else:\n",
        "                                          continue\n",
        "                                    #driver.back()    #    driver.execute_script(\"arguments[0].scrollIntoView();\", list_of_articles[i])\n",
        "                                    driver.back()\n",
        "                                else:\n",
        "                                  driver.back()\n",
        "                                  continue    \n",
        "                            except:\n",
        "                              driver.back()\n",
        "                              continue\n",
        "                                    \n",
        "                            #    driver.execute_script(\"arguments[0].scrollIntoView();\", list_of_articles[i])\n",
        "                        driver.back()\n",
        "                driver.back()\n",
        "            driver.back()\n",
        "            # button = driver.find_element_by_xpath(\"(//img[contains(@src,'/images/arrow-right.png')])[1]\")\n",
        "            # driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
        "            # button.click()\n",
        "            # time.sleep(10)\n",
        "\n",
        "    def get_author(self, reference):\n",
        "        author_detail = []\n",
        "        tapp = []\n",
        "        tapp[:0] = reference\n",
        "         #Separates author name and year, as year is mentioned in () with sentences and extracting year. \n",
        "        remove = \"1234567890\"\n",
        "        temp = \"\"\n",
        "        for i in range(len(tapp)):\n",
        "            if tapp[i] in remove:\n",
        "                break\n",
        "            else:\n",
        "                temp = temp + tapp[i]\n",
        "        author_name = temp.strip(\".(\")\n",
        "        try:\n",
        "          # Finding 4 digit in reference \n",
        "            match = re.search(r'\\d{4}', reference)\n",
        "          # Extracting year  \n",
        "            date = datetime.datetime.strptime(match.group(), '%Y').date()\n",
        "            year = date.year\n",
        "        except:\n",
        "            author_detail = None\n",
        "            return author_detail\n",
        "           # Spliting article and year as year is always after dot  \n",
        "        article_title = reference.split(\").\")\n",
        "        if len(article_title) > 2:\n",
        "            try:\n",
        "                title = re.search(\"(?P<url>https?://[^\\s]+)\", article_title[2]).group(\"url\")\n",
        "            except:\n",
        "                list_of_sentence = article_title[2].split(\".\")\n",
        "                title = list_of_sentence[0].strip(\" \")\n",
        "        else:\n",
        "            if len(article_title) == 1:\n",
        "                try:\n",
        "                    title = re.search(\"(?P<url>https?://[^\\s]+)\", article_title[2]).group(\"url\")\n",
        "                except:\n",
        "                    title = article_title[0]\n",
        "            else:\n",
        "                list_of_sen = article_title[1].split(\".\")\n",
        "                title = list_of_sen[0].strip(\" \")\n",
        "         #checking if author or year or author name any of the detail is not available it will none the author details        \n",
        "        if title == \"\" or year == \"\" or author_name == \"\":\n",
        "            author_detail = None\n",
        "            return author_detail\n",
        "        else:\n",
        "            author_detail.append(title)\n",
        "            author_detail.append(year)\n",
        "            author_detail.append(author_name)\n",
        "            return author_detail\n",
        "    #writing all information in csv file        \n",
        "\n",
        "    def writeintocsv(self, ref_details):\n",
        "        print(ref_details)\n",
        "        with open(r'/content/Book1.csv', 'a', encoding=\"utf-8\") as file:\n",
        "            writer = csv.writer(file)\n",
        "            if len(ref_details) <= 2:\n",
        "                pass\n",
        "            else:\n",
        "                writer.writerow([\"\", ref_details[0], ref_details[1], str(ref_details[2])])\n",
        "    # This checks file already exists or not on path\n",
        "object = In_Class_Assigment()\n",
        "isExist = os.path.exists(r'/content/Book1.csv')\n",
        "if isExist:\n",
        "    os.remove(r'/content/Book1.csv')\n",
        "    #  if file already exists it will append in that otherwise it will create new file and append data in it.\n",
        "with open(r'/content/Book1.csv', 'a+', newline='') as file:\n",
        "   # Object created to use csv.writer applications. \n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Journal Names\", \"Article Title\", \"Year\", \"Author\"])\n",
        "data_list=[(\"1968\", \"2019\",\"https://libproxy.library.unt.edu:4060/loi/19383703/year/1982\",\"Applied Behavior Analysis\"),(\"1958\", \"2019\",\"https://libproxy.library.unt.edu:4060/loi/19383711/year/\",\"Experimental Analysis of Behavior\")]\n",
        "object.get_data(data_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2zDoR0HClpE",
        "colab_type": "text"
      },
      "source": [
        "**Extracting References**\n",
        "\n",
        "7.Perspectives on Behavior Science\n",
        "\n",
        "8.Psychological Record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29eJpiBEClKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "import os\n",
        "import re,datetime\n",
        "import time\n",
        "import csv\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from google.colab import files\n",
        "from selenium import webdriver\n",
        "  \n",
        "class In_Class_Assigment():\n",
        "    def get_data(self,list_of_journal):\n",
        "        list_of_data=[]\n",
        "        print(list_of_journal)\n",
        "        obj = In_Class_Assigment()\n",
        "        # Launch chrome browser.\n",
        "        options = webdriver.ChromeOptions()\n",
        "        # Runs browser in background.\n",
        "        options.add_argument('--headless')\n",
        "        options.add_argument('--no-sandbox')\n",
        "        options.add_argument('--disable-dev-shm-usage')\n",
        "        options.add_argument('--disable-gpu')\n",
        "        options.add_argument(\"--window-size=1920,1080\")\n",
        "        options.add_argument(\"start-maximized\")\n",
        "        options.add_argument(\"disable-infobars\")  \n",
        "        options.add_argument(\"--disable-extensions\")\n",
        "        driver = webdriver.Chrome('chromedriver',options=options)\n",
        "        #This loop will run twice as there are two journals.\n",
        "        for journal in range(len(list_of_journal)):\n",
        "            with open(r'/content/Book1.csv', 'a', newline='') as file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow([list_of_journal[journal][3]])\n",
        "            list_of_data = list_of_journal[journal]\n",
        "            print(list_of_data)\n",
        "            print(list_of_data[2])\n",
        "            #driver.get is use to access url. \n",
        "            driver.get(list_of_data[2])\n",
        "            try:\n",
        "              if driver.find_element_by_xpath(\"(//button[@aria-expanded='false'])[8]\").is_displayed():\n",
        "                # finds year,but before that it checks it is already expanded or not.\n",
        "                 driver.find_element_by_xpath(\"//div[text()='Date Published']\").click()\n",
        "                 time.sleep(5)\n",
        "            except NoSuchElementException as msg:\n",
        "                print(\"No such element found\")\n",
        "            driver.find_element_by_xpath(\"//input[@id='start-year']\").clear()\n",
        "            driver.find_element_by_xpath(\"//input[@id='start-year']\").send_keys(list_of_data[0])\n",
        "            driver.find_element_by_xpath(\"//input[@id='end-year']\").clear()\n",
        "            driver.find_element_by_xpath(\"//input[@id='end-year']\").send_keys(list_of_data[1])\n",
        "            driver.find_element_by_xpath(\"(//input[@id='end-year']//following::input[@type='submit'])[1]\").click()\n",
        "            time.sleep(10)\n",
        "            #It find how many page are there on which articles are present.\n",
        "            total_pages = driver.find_element_by_xpath(\"(//span[@class='number-of-pages'])[1]\").text\n",
        "            count = int(total_pages)\n",
        "            for page in range(count-1):#count\n",
        "                list_of_articles = driver.find_elements_by_xpath(\"//h2//a[contains(@href,'/article/')]\")\n",
        "             # This loop will run for the number pages i.e. on which articles are available.  \n",
        "                for i in range(len(list_of_articles)):  # len(list_of_articles)\n",
        "                    time.sleep(5)\n",
        "                    driver.refresh()\n",
        "                    time.sleep(5)\n",
        "                    list_of_articles = driver.find_elements_by_xpath(\"//h2//a[contains(@href,'/article/')]\")\n",
        "            # This is use to scroll the page.\n",
        "                    driver.execute_script(\"arguments[0].scrollIntoView();\", list_of_articles[i])\n",
        "                    list_of_articles[i].click()\n",
        "            #This finds webelement i.e.location of references        \n",
        "                    list_of_ref = driver.find_elements_by_xpath(\"//p[contains(@class,'c-article-references__text')]\")\n",
        "                    if list_of_ref != []:\n",
        "                        for j in range(len(list_of_ref)):\n",
        "            # Actual content i.e. data which we want to extract from webpage is saved in reference_text in            \n",
        "                            reference_text = list_of_ref[j].text\n",
        "                            author = obj.get_author(reference_text)\n",
        "                            if author is None:\n",
        "                                continue\n",
        "                            author.append(list_of_data[3])\n",
        "                            obj.writeintocsv(author)\n",
        "                        driver.back()\n",
        "                    else:\n",
        "                        driver.back()\n",
        "                button=driver.find_element_by_xpath(\"(//img[contains(@src,'/images/arrow-right.png')])[1]\")\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", button)     \n",
        "                button.click()\n",
        "                time.sleep(10)\n",
        "\n",
        "    def get_author(self, reference):\n",
        "\n",
        "           author_detail=[]\n",
        "           tapp=[]\n",
        "           tapp[:0]=reference\n",
        "           #Separates author name and year, as year is mentioned in () with sentences and extracting year.  \n",
        "           remove=\"1234567890\"\n",
        "           temp=\"\"\n",
        "           for i in range(len(tapp)):\n",
        "              if tapp[i] in remove:\n",
        "                 break\n",
        "              else:\n",
        "                temp=temp+tapp[i]\n",
        "           author_name=temp.strip(\".(\")\n",
        "           try:\n",
        "             # Finding 4 digit in reference \n",
        "              match= re.search(r'\\d{4}',reference)\n",
        "              #Extracting year\n",
        "              date = datetime.datetime.strptime(match.group(), '%Y').date()\n",
        "              year=date.year\n",
        "           except:\n",
        "             author_detail=None\n",
        "             return author_detail\n",
        "             #Spliting article and year as year is always after dot\n",
        "           article_title=reference.split(\").\")\n",
        "           if len(article_title)>2:\n",
        "              try:\n",
        "                title=re.search(\"(?P<url>https?://[^\\s]+)\", article_title[2]).group(\"url\")\n",
        "              except:\n",
        "                list_of_sentence=article_title[2].split(\".\")\n",
        "                title=list_of_sentence[0].strip(\" \")\n",
        "           else:\n",
        "              if len(article_title)==1:\n",
        "                try:\n",
        "                  title=re.search(\"(?P<url>https?://[^\\s]+)\", article_title[2]).group(\"url\")\n",
        "                except:\n",
        "                   title=article_title[0]\n",
        "              else:\n",
        "                list_of_sen=article_title[1].split(\".\")\n",
        "                title=list_of_sen[0].strip(\" \")    \n",
        "                #checking if author or year or author name any of the detail is not available it will none the author details\n",
        "           if title==\"\" or year==\"\" or author_name==\"\":\n",
        "                author_detail=None\n",
        "                return author_detail\n",
        "           else:\n",
        "                author_detail.append(title)\n",
        "                author_detail.append(year)\n",
        "                author_detail.append(author_name)\n",
        "                return author_detail\n",
        "                \n",
        "               #writing all information in csv file\n",
        "    def writeintocsv(self,ref_details):\n",
        "        with open(r'/content/Book1.csv', 'a', newline='') as file:\n",
        "                writer = csv.writer(file)\n",
        "                if len(ref_details)<=2:\n",
        "                   pass\n",
        "                else:\n",
        "                   writer.writerow([\"\",ref_details[0],ref_details[1],str(ref_details[2]).strip('[]')])\n",
        "#This checks file already exists or not on path\n",
        "object = In_Class_Assigment()\n",
        "isExist = os.path.exists('/content/Book1.csv')\n",
        "if isExist:\n",
        "         os.remove('/content/Book1.csv')\n",
        "#  if file already exists it will append in that otherwise it will create new file and append data in it.         \n",
        "with open(r'/content/Book1.csv', 'a+', newline='') as file:\n",
        "# Object created to use csv.writer applications.  \n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow([\"Journal Names\",\"Article Title\",\"Year\",\"Author\"]) \n",
        "data_list=[(\"1937\", \"2019\",\"https://link.springer.com/search?query=&search-within=Journal&facet-journal-id=40732\",\"Psychological Record\")]\n",
        "object.get_data(data_list)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}