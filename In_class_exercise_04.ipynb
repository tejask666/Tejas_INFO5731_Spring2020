{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of In-class-exercise-04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejask666/Tejas_INFO5731_Spring2020/blob/master/In_class_exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuX00KHNeSpw",
        "colab_type": "text"
      },
      "source": [
        "# **The fourth in-class-exercise**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vTOb03hG1f",
        "colab_type": "text"
      },
      "source": [
        "# 1. Text Data Preprocessing\n",
        "\n",
        "Here is a [legal case](https://github.com/unt-iialab/INFO5731_Spring2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "## 1.1 Basic feature extraction using text data\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "## 1.2 Basic Text Pre-processing of text data\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "## 1.3 Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above.\n",
        "\n",
        "\n",
        "## 1.4 Advance Text Processing\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 2-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR0L3_CreM_A",
        "colab_type": "code",
        "outputId": "f63165e1-3462-4b83-dd27-551bc69948d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "!apt-get update\n",
        "import os\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "from autocorrect import Speller\n",
        "import nltk\n",
        "import shutil\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "from pandas import DataFrame\n",
        "import spacy\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from google.colab import files\n",
        "from selenium import webdriver\n",
        "  \n",
        "class In_Class_Assigment():\n",
        "        stopwordlist = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "                            \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\",\n",
        "                            \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\",\n",
        "                            \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
        "                            \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\",\n",
        "                            \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\n",
        "                            \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\",\n",
        "                            \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\",\n",
        "                            \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\",\n",
        "                            \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\",\n",
        "                            \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
        "        def get_data(self):\n",
        "             nltk.download('punkt')\n",
        "             options = webdriver.ChromeOptions()\n",
        "             options.add_argument('--headless')\n",
        "             options.add_argument('--no-sandbox')\n",
        "             options.add_argument('--disable-dev-shm-usage')\n",
        "             driver = webdriver.Chrome('chromedriver',options=options)\n",
        "             driver.get(\"https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\")\n",
        "             content=driver.find_element_by_tag_name('pre').text\n",
        "             return content\n",
        "        \n",
        "        def delete_file_if_exist(self):\n",
        "          isExist = os.path.exists('/content/ProcessedData.csv')\n",
        "          if isExist:\n",
        "             os.remove('/content/ProcessedData.csv')\n",
        "\n",
        "        def count_sentences_and_words(self,content):\n",
        "            list_of_sentences=content.split('.')\n",
        "            char_count=0\n",
        "            for i in list_of_sentences:\n",
        "                char_count= char_count+len(i)\n",
        "            print(\"\\nnumber of sentences are:\"+str(content.count('.')))\n",
        "            print(\"\\nnumber of words are:\"+str(len(content.split())))\n",
        "            print(\"\\nnumber of characters are:\"+str(char_count))\n",
        "        \n",
        "        def calculate_avg_word_len(self,content):\n",
        "            words=content.split()\n",
        "            average = sum(len(word) for word in words) / len(words)\n",
        "            print(\"\\naverage word length is:\"+ str(average))\n",
        "\n",
        "        def calculate_stopword(self,content):\n",
        "            stopword_count=0\n",
        "            textlist = content.split()\n",
        "            for i in range(len(textlist)):\n",
        "              if textlist[i] in In_Class_Assigment.stopwordlist:\n",
        "                stopword_count=stopword_count+1\n",
        "            print(\"\\nnumber of stop words are:\"+str(stopword_count))\n",
        "\n",
        "        def calculate_specifics(self,content):\n",
        "            special_char_count=0\n",
        "            numeric_count=0\n",
        "            uppercase_count=0\n",
        "            special_char_list=\"!#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
        "            numrice_values=\"0123456789\"\n",
        "            words=content.split()\n",
        "            for i in range(len(words)):\n",
        "              for j in range(len(words[i])):\n",
        "                if words[i][j] in special_char_list:\n",
        "                    special_char_count = special_char_count + 1\n",
        "                elif words[i][j] in numrice_values:\n",
        "                    numeric_count = numeric_count + 1\n",
        "                elif words[i][j].isupper():\n",
        "                    uppercase_count = uppercase_count + 1\n",
        "            print(\"\\nnumber of upper case characters are:\"+str(uppercase_count))\n",
        "            print(\"\\nnumber of special characters are:\"+str(special_char_count))\n",
        "            print(\"\\nnumber of numeric values are:\"+str(numeric_count))\n",
        "\n",
        "        def removeallpunctuation(self,content):\n",
        "            textstring = content.split('.')\n",
        "            temp = ''\n",
        "            removetext = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "            for i in range(len(textstring)):\n",
        "              for j in range(len(textstring[i])):\n",
        "                 if textstring[i][j] in removetext:\n",
        "                     pass\n",
        "                 else:\n",
        "                    temp = temp+textstring[i][j]\n",
        "            return temp\n",
        "\n",
        "        def remove_stop_words(self, content):\n",
        "            temp = ''\n",
        "            textlist = word_tokenize(content)\n",
        "            for i in range(len(textlist)):\n",
        "                if textlist[i] in In_Class_Assigment.stopwordlist:\n",
        "                    pass\n",
        "                else:\n",
        "                    temp = temp + \" \" + textlist[i]\n",
        "            return temp\n",
        "        \n",
        "        def lemma_and_stem(self,sentence):\n",
        "            temp=''\n",
        "            #nlp = spacy.load(\"en_core_web_sm\")\n",
        "            #tokanized_text = nlp(sentence)\n",
        "            for token in sentence:\n",
        "                ps = PorterStemmer()\n",
        "                word=ps.stem(token.lemma_)\n",
        "                temp = temp + \" \" + word\n",
        "            return temp\n",
        "\n",
        "        def tokanize_content(self,content):\n",
        "          nlp = spacy.load(\"en_core_web_sm\")\n",
        "          tokanized_text = nlp(content)\n",
        "          return tokanized_text\n",
        "\n",
        "        def remove_frequent_and_rare_word(self,content):\n",
        "          temp=''\n",
        "          content_word_list=content.split()\n",
        "          frequent_words = pd.Series(' '.join(content_word_list).split()).value_counts()[:10]\n",
        "          rare_words=pd.Series(' '.join(content_word_list).split()).value_counts()[-10:]\n",
        "          for i in range(len(content_word_list)):\n",
        "            if content_word_list[i] in frequent_words or content_word_list[i] in rare_words:\n",
        "               pass\n",
        "            else:\n",
        "              temp=temp+\" \"+content_word_list[i]\n",
        "          return temp\n",
        "\n",
        "        def spelling_correction(self,content):\n",
        "           temp=''\n",
        "           word_list=content.split()\n",
        "           spell = Speller(lang='en')\n",
        "           for item in range(len(word_list)):\n",
        "              corrected_word = spell(word_list[item])\n",
        "              temp=temp+\" \"+corrected_word\n",
        "           return temp\n",
        "           \n",
        "        def writeintocsv(self,text,i):\n",
        "            dataset = {'data': text}\n",
        "            df = DataFrame(dataset, columns=['data'], index=[i])\n",
        "            export_csv = df.loc[[i]].to_csv('ProcessedData.csv', index=None,header=0,mode='a')  \n",
        "\n",
        "        def text_preprocessing(self,content):         \n",
        "          cleaned_whole_content=''\n",
        "          object=In_Class_Assigment()\n",
        "          object.delete_file_if_exist()\n",
        "          lower_case_content=content.lower()\n",
        "          sentences=lower_case_content.split('.')\n",
        "          for i in range(len(sentences)-1):\n",
        "              removed_pun=object.removeallpunctuation(sentences[i])\n",
        "              removed_stopword=object.remove_stop_words(removed_pun)\n",
        "              removed_frequent_rare_word=object.remove_frequent_and_rare_word(removed_stopword)\n",
        "              if len(removed_frequent_rare_word) is not 0: \n",
        "                 spellings_checked=object.spelling_correction(removed_frequent_rare_word)\n",
        "              else:\n",
        "                 spellings_checked=object.spelling_correction(removed_stopword)  \n",
        "              if len(spellings_checked) is not 0: \n",
        "                 tokanized_content=object.tokanize_content(spellings_checked)\n",
        "              elif len(removed_frequent_rare_word) is not 0:\n",
        "                 tokanized_content=object.tokanize_content(removed_frequent_rare_word)\n",
        "              else:\n",
        "                 tokanized_content=object.tokanize_content(removed_stopword)\n",
        "              text_processed_data=object.lemma_and_stem(tokanized_content)\n",
        "              cleaned_whole_content=cleaned_whole_content+str(text_processed_data)\n",
        "              cleaned_whole_content=cleaned_whole_content.replace(\"   \",\" \")\n",
        "              object.writeintocsv(str(text_processed_data).lstrip(),i)\n",
        "          return cleaned_whole_content\n",
        "       \n",
        "        def calculate_term_frequency(self,cleaned_data):\n",
        "          list= cleaned_data.split()\n",
        "          str2 = [] \n",
        "          for i in range(len(list)):              \n",
        "              if list[i] not in str2: \n",
        "                  str2.append(list[i])  \n",
        "          for i in range(0, len(str2)): \n",
        "             print('Frequency of', str2[i], 'is :', list.count(str2[i]))  \n",
        "        \n",
        "        def calculate_ngram(self,cleaned_data,n):\n",
        "          input_list= cleaned_data.split()\n",
        "          mapped=zip(*[input_list[i:] for i in range(n)])\n",
        "          counts = Counter(mapped)\n",
        "          dictionary=dict(counts.most_common())\n",
        "          dictionary={k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1],reverse=True)}\n",
        "          return list(islice(dictionary.items(),10))\n",
        "\n",
        "def main():\n",
        "          object=In_Class_Assigment()\n",
        "          content=object.get_data()\n",
        "          object.count_sentences_and_words(content)\n",
        "          object.calculate_avg_word_len(content)\n",
        "          object.calculate_specifics(content)\n",
        "          object.calculate_stopword(content)\n",
        "          processed_output=object.text_preprocessing(content)\n",
        "          object.calculate_term_frequency(processed_output)\n",
        "          print(\"top 10 1-gram are as follows\"+str(object.calculate_ngram(processed_output,1)))\n",
        "          print(\"top 10 2-gram are as follows:\"+str(object.calculate_ngram(processed_output,2)))\n",
        "\n",
        "if __name__=='__main__':\n",
        "             main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.31)]\r                                                                               \rHit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.31)]\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.31)]\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.31)]\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.31)]\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r0% [3 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (80.0.3987.87-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 103 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "number of sentences are:291\n",
            "\n",
            "number of words are:3707\n",
            "\n",
            "number of characters are:20161\n",
            "\n",
            "average word length is:4.510385756676558\n",
            "\n",
            "number of upper case characters are:695\n",
            "\n",
            "number of special characters are:774\n",
            "\n",
            "number of numeric values are:356\n",
            "\n",
            "number of stop words are:1679\n",
            "Frequency of 5 is : 8\n",
            "Frequency of ala is : 15\n",
            "Frequency of 740 is : 2\n",
            "Frequency of suprem is : 1\n",
            "Frequency of court is : 19\n",
            "Frequency of alabama is : 1\n",
            "Frequency of adam is : 1\n",
            "Frequency of v is : 22\n",
            "Frequency of tanner is : 1\n",
            "Frequency of horson is : 1\n",
            "Frequency of june is : 1\n",
            "Frequency of term is : 10\n",
            "Frequency of 1843 is : 2\n",
            "Frequency of synopsi is : 1\n",
            "Frequency of writ is : 3\n",
            "Frequency of error is : 5\n",
            "Frequency of circuit is : 9\n",
            "Frequency of summer is : 2\n",
            "Frequency of grow is : 15\n",
            "Frequency of 4 is : 6\n",
            "Frequency of case is : 23\n",
            "Frequency of cite is : 11\n",
            "Frequency of headnot is : 3\n",
            "Frequency of 2 is : 12\n",
            "Frequency of creditor is : 3\n",
            "Frequency of ’ is : 7\n",
            "Frequency of remedi is : 1\n",
            "Frequency of lien is : 18\n",
            "Frequency of prioriti is : 1\n",
            "Frequency of st is : 1\n",
            "Frequency of 1821 is : 2\n",
            "Frequency of prohibit is : 3\n",
            "Frequency of levi is : 29\n",
            "Frequency of crop is : 34\n",
            "Frequency of gather is : 14\n",
            "Frequency of attach is : 11\n",
            "Frequency of favor is : 3\n",
            "Frequency of fi is : 1\n",
            "Frequency of fa is : 1\n",
            "Frequency of 1 is : 8\n",
            "Frequency of trial is : 3\n",
            "Frequency of right is : 18\n",
            "Frequency of properti is : 6\n",
            "Frequency of statut is : 6\n",
            "Frequency of novemb is : 1\n",
            "Frequency of 1840 is : 3\n",
            "Frequency of execut is : 35\n",
            "Frequency of issu is : 4\n",
            "Frequency of suit is : 1\n",
            "Frequency of plaintiff is : 13\n",
            "Frequency of requir is : 3\n",
            "Frequency of sheriff is : 5\n",
            "Frequency of counti is : 2\n",
            "Frequency of make is : 9\n",
            "Frequency of good is : 5\n",
            "Frequency of c is : 9\n",
            "Frequency of allen is : 3\n",
            "Frequency of harrison is : 9\n",
            "Frequency of other is : 1\n",
            "Frequency of sum is : 1\n",
            "Frequency of thirtyseven is : 1\n",
            "Frequency of hundr is : 2\n",
            "Frequency of seventyseven is : 1\n",
            "Frequency of 80100 is : 1\n",
            "Frequency of dollar is : 3\n",
            "Frequency of besid is : 1\n",
            "Frequency of cost is : 1\n",
            "Frequency of thirti is : 1\n",
            "Frequency of bale is : 2\n",
            "Frequency of cotton is : 11\n",
            "Frequency of claim is : 2\n",
            "Frequency of bond is : 1\n",
            "Frequency of give is : 7\n",
            "Frequency of tri is : 8\n",
            "Frequency of question is : 4\n",
            "Frequency of liabil is : 2\n",
            "Frequency of submit is : 1\n",
            "Frequency of juri is : 4\n",
            "Frequency of bill is : 3\n",
            "Frequency of except is : 3\n",
            "Frequency of seal is : 1\n",
            "Frequency of instanc is : 2\n",
            "Frequency of prove is : 2\n",
            "Frequency of recov is : 1\n",
            "Frequency of judgment is : 5\n",
            "Frequency of octob is : 1\n",
            "Frequency of 1839 is : 1\n",
            "Frequency of 741 is : 1\n",
            "Frequency of thereon is : 1\n",
            "Frequency of 7th is : 1\n",
            "Frequency of nov is : 2\n",
            "Frequency of thereaft is : 1\n",
            "Frequency of alia is : 1\n",
            "Frequency of pluri is : 1\n",
            "Frequency of fieri is : 3\n",
            "Frequency of facia is : 2\n",
            "Frequency of regularli is : 1\n",
            "Frequency of time is : 7\n",
            "Frequency of plantat is : 1\n",
            "Frequency of cultiv is : 1\n",
            "Frequency of hand is : 1\n",
            "Frequency of servic is : 1\n",
            "Frequency of twentysecond is : 1\n",
            "Frequency of may is : 10\n",
            "Frequency of involv is : 2\n",
            "Frequency of amount is : 1\n",
            "Frequency of consist is : 1\n",
            "Frequency of one is : 2\n",
            "Frequency of twenti is : 1\n",
            "Frequency of acr is : 1\n",
            "Frequency of promis is : 1\n",
            "Frequency of oblig is : 1\n",
            "Frequency of use is : 2\n",
            "Frequency of claimant is : 14\n",
            "Frequency of save is : 1\n",
            "Frequency of suffer is : 1\n",
            "Frequency of indors is : 4\n",
            "Frequency of matur is : 3\n",
            "Frequency of undertook is : 1\n",
            "Frequency of deliv is : 2\n",
            "Frequency of gainesvil is : 1\n",
            "Frequency of tennesse is : 1\n",
            "Frequency of septemb is : 1\n",
            "Frequency of bring is : 3\n",
            "Frequency of possess is : 12\n",
            "Frequency of take is : 12\n",
            "Frequency of absent is : 1\n",
            "Frequency of dispos is : 3\n",
            "Frequency of without is : 4\n",
            "Frequency of consent is : 2\n",
            "Frequency of admit is : 3\n",
            "Frequency of contract is : 12\n",
            "Frequency of faith is : 3\n",
            "Frequency of charg is : 4\n",
            "Frequency of convey is : 3\n",
            "Frequency of adduc is : 2\n",
            "Frequency of upon is : 8\n",
            "Frequency of obtain is : 1\n",
            "Frequency of control is : 1\n",
            "Frequency of subject is : 7\n",
            "Frequency of attorney is : 1\n",
            "Frequency of law is : 16\n",
            "Frequency of firm is : 1\n",
            "Frequency of r is : 2\n",
            "Frequency of h is : 1\n",
            "Frequency of smith is : 1\n",
            "Frequency of follow is : 3\n",
            "Frequency of point is : 4\n",
            "Frequency of must is : 3\n",
            "Frequency of immatur is : 2\n",
            "Frequency of state is : 5\n",
            "Frequency of insist is : 2\n",
            "Frequency of sale is : 6\n",
            "Frequency of common is : 7\n",
            "Frequency of could is : 5\n",
            "Frequency of sell is : 6\n",
            "Frequency of talk is : 2\n",
            "Frequency of rep is : 16\n",
            "Frequency of 361 is : 1\n",
            "Frequency of bo is : 2\n",
            "Frequency of p is : 3\n",
            "Frequency of 307 is : 1\n",
            "Frequency of 6 is : 3\n",
            "Frequency of east is : 2\n",
            "Frequency of 604 is : 2\n",
            "Frequency of note is : 1\n",
            "Frequency of john is : 9\n",
            "Frequency of 418 is : 1\n",
            "Frequency of 422 is : 2\n",
            "Frequency of 7 is : 2\n",
            "Frequency of mass is : 1\n",
            "Frequency of 34 is : 1\n",
            "Frequency of statu is : 1\n",
            "Frequency of aik is : 3\n",
            "Frequency of dig is : 4\n",
            "Frequency of § is : 2\n",
            "Frequency of 41 is : 1\n",
            "Frequency of 167 is : 3\n",
            "Frequency of forbid is : 3\n",
            "Frequency of 742 is : 1\n",
            "Frequency of receiv is : 1\n",
            "Frequency of strict is : 1\n",
            "Frequency of construct is : 2\n",
            "Frequency of mere is : 5\n",
            "Frequency of inhibit is : 2\n",
            "Frequency of 3 is : 7\n",
            "Frequency of purport is : 1\n",
            "Frequency of executori is : 1\n",
            "Frequency of agreement is : 1\n",
            "Frequency of act is : 9\n",
            "Frequency of do is : 2\n",
            "Frequency of order is : 1\n",
            "Frequency of invest is : 1\n",
            "Frequency of chit is : 1\n",
            "Frequency of con is : 2\n",
            "Frequency of 112 is : 2\n",
            "Frequency of 207 is : 1\n",
            "Frequency of 338 is : 1\n",
            "Frequency of 424 is : 1\n",
            "Frequency of wend is : 1\n",
            "Frequency of 26 is : 1\n",
            "Frequency of 13 is : 1\n",
            "Frequency of 235 is : 1\n",
            "Frequency of 8 is : 3\n",
            "Frequency of dowl is : 1\n",
            "Frequency of 693 is : 1\n",
            "Frequency of matter is : 3\n",
            "Frequency of liabl is : 1\n",
            "Frequency of seiz is : 2\n",
            "Frequency of debt is : 2\n",
            "Frequency of chanceri is : 1\n",
            "Frequency of would is : 5\n",
            "Frequency of compel is : 1\n",
            "Frequency of specif is : 1\n",
            "Frequency of perform is : 1\n",
            "Frequency of ' is : 4\n",
            "Frequency of also is : 4\n",
            "Frequency of objection is : 1\n",
            "Frequency of decid is : 2\n",
            "Frequency of disput is : 1\n",
            "Frequency of fact is : 3\n",
            "Frequency of w is : 4\n",
            "Frequency of m is : 2\n",
            "Frequency of murphi is : 1\n",
            "Frequency of g is : 1\n",
            "Frequency of jone is : 2\n",
            "Frequency of defendantcit is : 1\n",
            "Frequency of declar is : 2\n",
            "Frequency of plant is : 7\n",
            "Frequency of contend is : 1\n",
            "Frequency of defend is : 9\n",
            "Frequency of restrain is : 1\n",
            "Frequency of destroy is : 1\n",
            "Frequency of injunct is : 1\n",
            "Frequency of away is : 3\n",
            "Frequency of short is : 1\n",
            "Frequency of whenev is : 1\n",
            "Frequency of temporarili is : 1\n",
            "Frequency of suspend is : 2\n",
            "Frequency of withdraw is : 1\n",
            "Frequency of lose is : 2\n",
            "Frequency of whimpl is : 4\n",
            "Frequency of foot is : 4\n",
            "Frequency of 216 is : 1\n",
            "Frequency of wash is : 1\n",
            "Frequency of 66 is : 1\n",
            "Frequency of 130 is : 1\n",
            "Frequency of sever is : 3\n",
            "Frequency of remov is : 3\n",
            "Frequency of latter is : 2\n",
            "Frequency of titl is : 4\n",
            "Frequency of former is : 2\n",
            "Frequency of opinion is : 4\n",
            "Frequency of collier is : 1\n",
            "Frequency of j is : 3\n",
            "Frequency of doubt is : 5\n",
            "Frequency of exist is : 3\n",
            "Frequency of mortgag is : 5\n",
            "Frequency of interest is : 2\n",
            "Frequency of vest is : 1\n",
            "Frequency of either is : 1\n",
            "Frequency of immedi is : 1\n",
            "Frequency of futur is : 2\n",
            "Frequency of proposit is : 2\n",
            "Frequency of frequent is : 2\n",
            "Frequency of assum is : 2\n",
            "Frequency of unquestion is : 2\n",
            "Frequency of inquiri is : 2\n",
            "Frequency of gener is : 2\n",
            "Frequency of whether is : 6\n",
            "Frequency of fraud is : 1\n",
            "Frequency of 29 is : 1\n",
            "Frequency of cha is : 1\n",
            "Frequency of chattel is : 2\n",
            "Frequency of transferr is : 1\n",
            "Frequency of parol is : 2\n",
            "Frequency of write is : 3\n",
            "Frequency of chitti is : 1\n",
            "Frequency of 2412 is : 1\n",
            "Frequency of 332 is : 1\n",
            "Frequency of stewart is : 2\n",
            "Frequency of doughti is : 2\n",
            "Frequency of 9 is : 6\n",
            "Frequency of 743 is : 1\n",
            "Frequency of austin is : 2\n",
            "Frequency of sawyer is : 2\n",
            "Frequency of cow is : 2\n",
            "Frequency of 39 is : 2\n",
            "Frequency of see is : 2\n",
            "Frequency of braveri is : 1\n",
            "Frequency of lee is : 1\n",
            "Frequency of alsoon is : 1\n",
            "Frequency of last is : 2\n",
            "Frequency of set is : 1\n",
            "Frequency of inclin is : 1\n",
            "Frequency of think is : 3\n",
            "Frequency of evid is : 3\n",
            "Frequency of rather is : 1\n",
            "Frequency of absolut is : 1\n",
            "Frequency of mercantil is : 1\n",
            "Frequency of estat is : 1\n",
            "Frequency of grantor is : 2\n",
            "Frequency of prevent is : 3\n",
            "Frequency of consid is : 4\n",
            "Frequency of assert is : 1\n",
            "Frequency of power is : 1\n",
            "Frequency of year is : 3\n",
            "Frequency of unless is : 1\n",
            "Frequency of reliev is : 1\n",
            "Frequency of engag is : 1\n",
            "Frequency of pretend is : 1\n",
            "Frequency of satisfi is : 2\n",
            "Frequency of parti is : 1\n",
            "Frequency of dri is : 1\n",
            "Frequency of shall is : 4\n",
            "Frequency of prevail is : 1\n",
            "Frequency of present is : 1\n",
            "Frequency of oper is : 2\n",
            "Frequency of previou is : 2\n",
            "Frequency of inquir is : 1\n",
            "Frequency of prepar is : 1\n",
            "Frequency of market is : 1\n",
            "Frequency of warehous is : 1\n",
            "Frequency of trespass is : 1\n",
            "Frequency of acquir is : 2\n",
            "Frequency of absenc is : 1\n",
            "Frequency of conced is : 2\n",
            "Frequency of truth is : 1\n",
            "Frequency of nulliti is : 1\n",
            "Frequency of never is : 2\n",
            "Frequency of interfer is : 1\n",
            "Frequency of subsequ is : 1\n",
            "Frequency of approv is : 1\n",
            "Frequency of clear is : 1\n",
            "Frequency of 744 is : 1\n",
            "Frequency of noth is : 3\n",
            "Frequency of equit is : 1\n",
            "Frequency of redeem is : 1\n",
            "Frequency of pay is : 2\n",
            "Frequency of coupl is : 2\n",
            "Frequency of equiti is : 2\n",
            "Frequency of nake is : 1\n",
            "Frequency of hold is : 1\n",
            "Frequency of reach is : 1\n",
            "Frequency of ordinari is : 1\n",
            "Frequency of perkin is : 2\n",
            "Frequency of juliott is : 1\n",
            "Frequency of hayfield is : 2\n",
            "Frequency of porter is : 1\n",
            "Frequency of 182 is : 2\n",
            "Frequency of -pron- is : 1\n",
            "Frequency of back is : 1\n",
            "Frequency of defeat is : 1\n",
            "Frequency of moot is : 1\n",
            "Frequency of corn is : 3\n",
            "Frequency of mr is : 1\n",
            "Frequency of remark is : 1\n",
            "Frequency of bacon is : 1\n",
            "Frequency of ground is : 2\n",
            "Frequency of harvest is : 1\n",
            "Frequency of entitl is : 1\n",
            "Frequency of enter is : 3\n",
            "Frequency of purpos is : 2\n",
            "Frequency of cut is : 1\n",
            "Frequency of carri is : 1\n",
            "Frequency of \" is : 7\n",
            "Frequency of ut is : 1\n",
            "Frequency of supra is : 1\n",
            "Frequency of pool is : 1\n",
            "Frequency of 368 is : 1\n",
            "Frequency of 397 is : 1\n",
            "Frequency of n is : 3\n",
            "Frequency of seem is : 1\n",
            "Frequency of support is : 1\n",
            "Frequency of posit is : 2\n",
            "Frequency of unrip is : 1\n",
            "Frequency of wheat is : 3\n",
            "Frequency of editor is : 1\n",
            "Frequency of say is : 2\n",
            "Frequency of learn is : 1\n",
            "Frequency of comment is : 1\n",
            "Frequency of unnecessari is : 1\n",
            "Frequency of stand is : 1\n",
            "Frequency of first is : 1\n",
            "Frequency of person is : 2\n",
            "Frequency of express is : 1\n",
            "Frequency of remain is : 1\n",
            "Frequency of soil is : 2\n",
            "Frequency of owe is : 1\n",
            "Frequency of growth is : 1\n",
            "Frequency of thu is : 1\n",
            "Frequency of eo is : 1\n",
            "Frequency of debtor is : 3\n",
            "Frequency of 745 is : 1\n",
            "Frequency of intim is : 1\n",
            "Frequency of connect is : 3\n",
            "Frequency of effect is : 3\n",
            "Frequency of destruct is : 1\n",
            "Frequency of principl is : 2\n",
            "Frequency of fulli is : 1\n",
            "Frequency of establish is : 1\n",
            "Frequency of mansonri is : 1\n",
            "Frequency of turrel is : 1\n",
            "Frequency of presid is : 1\n",
            "Frequency of bank is : 1\n",
            "Frequency of unit is : 1\n",
            "Frequency of assigne is : 1\n",
            "Frequency of citat is : 5\n",
            "Frequency of contain is : 1\n",
            "Frequency of wood is : 1\n",
            "Frequency of gari is : 1\n",
            "Frequency of et is : 1\n",
            "Frequency of al is : 1\n",
            "Frequency of compet is : 1\n",
            "Frequency of legislatur is : 3\n",
            "Frequency of unlaw is : 1\n",
            "Frequency of particular is : 1\n",
            "Frequency of condit is : 2\n",
            "Frequency of chang is : 1\n",
            "Frequency of still is : 2\n",
            "Frequency of continu is : 1\n",
            "Frequency of indic is : 1\n",
            "Frequency of intent is : 2\n",
            "Frequency of suppos is : 3\n",
            "Frequency of induc is : 1\n",
            "Frequency of intend is : 1\n",
            "Frequency of creat is : 1\n",
            "Frequency of author is : 2\n",
            "Frequency of silent is : 1\n",
            "Frequency of word is : 2\n",
            "Frequency of viz is : 1\n",
            "Frequency of regard is : 2\n",
            "Frequency of potent is : 1\n",
            "Frequency of retrospect is : 1\n",
            "Frequency of refer is : 4\n",
            "Frequency of postpon is : 2\n",
            "Frequency of relat is : 1\n",
            "Frequency of event is : 1\n",
            "Frequency of place is : 1\n",
            "Frequency of expressli is : 1\n",
            "Frequency of consequ is : 1\n",
            "Frequency of paramount is : 1\n",
            "Frequency of exert is : 1\n",
            "Frequency of assumpt is : 1\n",
            "Frequency of materi is : 1\n",
            "Frequency of determin is : 1\n",
            "Frequency of instruct is : 1\n",
            "Frequency of find is : 3\n",
            "Frequency of accord is : 1\n",
            "Frequency of ever is : 1\n",
            "Frequency of bona is : 1\n",
            "Frequency of fide is : 1\n",
            "Frequency of necessari is : 2\n",
            "Frequency of proprieti is : 1\n",
            "Frequency of result is : 3\n",
            "Frequency of affirm is : 2\n",
            "Frequency of dissent is : 1\n",
            "Frequency of osmond is : 1\n",
            "Frequency of clay is : 1\n",
            "Frequency of 210 is : 1\n",
            "Frequency of 46 is : 1\n",
            "Frequency of enquiri is : 1\n",
            "Frequency of though is : 1\n",
            "Frequency of apprehend is : 1\n",
            "Frequency of difficult is : 2\n",
            "Frequency of maintain is : 1\n",
            "Frequency of suffici is : 1\n",
            "Frequency of doubtless is : 1\n",
            "Frequency of practic is : 1\n",
            "Frequency of real is : 1\n",
            "Frequency of exempt is : 2\n",
            "Frequency of speci is : 1\n",
            "Frequency of appear is : 1\n",
            "Frequency of defer is : 1\n",
            "Frequency of argument is : 1\n",
            "Frequency of “ is : 3\n",
            "Frequency of therefor is : 1\n",
            "Frequency of non is : 1\n",
            "Frequency of sequitur is : 1\n",
            "Frequency of put is : 2\n",
            "Frequency of 747 is : 1\n",
            "Frequency of mean is : 1\n",
            "Frequency of confirm is : 1\n",
            "Frequency of correct is : 2\n",
            "Frequency of view is : 2\n",
            "Frequency of languag is : 1\n",
            "Frequency of employ is : 1\n",
            "Frequency of major is : 1\n",
            "Frequency of secur is : 2\n",
            "Frequency of frustrat is : 1\n",
            "Frequency of whilst is : 1\n",
            "Frequency of anomali is : 1\n",
            "Frequency of protect is : 1\n",
            "Frequency of gift is : 1\n",
            "Frequency of provid is : 1\n",
            "Frequency of feel is : 1\n",
            "Frequency of thorough is : 1\n",
            "Frequency of convict is : 1\n",
            "Frequency of loss is : 1\n",
            "Frequency of temporari is : 1\n",
            "Frequency of suspens is : 1\n",
            "Frequency of ceas is : 1\n",
            "Frequency of wl is : 1\n",
            "Frequency of 284 is : 1\n",
            "Frequency of end is : 1\n",
            "Frequency of document is : 1\n",
            "Frequency of © is : 1\n",
            "Frequency of 2019 is : 1\n",
            "Frequency of thomson is : 1\n",
            "Frequency of renter is : 1\n",
            "Frequency of origin is : 1\n",
            "Frequency of u is : 1\n",
            "Frequency of govern is : 1\n",
            "Frequency of work is : 1\n",
            "Frequency of treatment is : 4\n",
            "Frequency of date is : 1\n",
            "Frequency of type is : 2\n",
            "Frequency of depth is : 2\n",
            "Frequency of booker is : 1\n",
            "Frequency of adm is : 1\n",
            "Frequency of x is : 1\n",
            "Frequency of 55 is : 1\n",
            "Frequency of 266 is : 1\n",
            "Frequency of 271 is : 1\n",
            "Frequency of trover is : 3\n",
            "Frequency of convers is : 3\n",
            "Frequency of count is : 1\n",
            "Frequency of appeal is : 6\n",
            "Frequency of hale is : 2\n",
            "Frequency of hon is : 6\n",
            "Frequency of scaffold is : 1\n",
            "Frequency of dec is : 1\n",
            "Frequency of 1876 is : 1\n",
            "Frequency of — is : 11\n",
            "Frequency of lehrman is : 1\n",
            "Frequency of durr is : 1\n",
            "Frequency of co is : 1\n",
            "Frequency of marshal is : 1\n",
            "Frequency of 47 is : 1\n",
            "Frequency of 362 is : 1\n",
            "Frequency of 376 is : 1\n",
            "Frequency of citi is : 2\n",
            "Frequency of montgomeri is : 2\n",
            "Frequency of d is : 3\n",
            "Frequency of cunningham is : 2\n",
            "Frequency of jan is : 3\n",
            "Frequency of 1872 is : 1\n",
            "Frequency of bibb is : 1\n",
            "Frequency of jann is : 1\n",
            "Frequency of 45 is : 1\n",
            "Frequency of 329 is : 1\n",
            "Frequency of 334 is : 1\n",
            "Frequency of garnish is : 1\n",
            "Frequency of wage is : 1\n",
            "Frequency of waiver is : 1\n",
            "Frequency of 1871 is : 1\n",
            "Frequency of mackenzi is : 1\n",
            "Frequency of lamprey is : 1\n",
            "Frequency of 31 is : 1\n",
            "Frequency of 526 is : 1\n",
            "Frequency of 527 is : 1\n",
            "Frequency of harbour is : 1\n",
            "Frequency of 1858 is : 1\n",
            "Frequency of evan is : 1\n",
            "Frequency of lama is : 1\n",
            "Frequency of 21 is : 1\n",
            "Frequency of 333 is : 1\n",
            "Frequency of 335 is : 1\n",
            "Frequency of + is : 2\n",
            "Frequency of tautaug is : 1\n",
            "Frequency of b is : 2\n",
            "Frequency of moor is : 1\n",
            "Frequency of jun is : 1\n",
            "Frequency of 1852 is : 1\n",
            "Frequency of dewey is : 1\n",
            "Frequency of bowman is : 1\n",
            "Frequency of cal is : 2\n",
            "Frequency of 145 is : 1\n",
            "Frequency of 147 is : 1\n",
            "Frequency of jacob is : 1\n",
            "Frequency of cohen is : 2\n",
            "Frequency of revers is : 1\n",
            "Frequency of reason is : 1\n",
            "Frequency of far is : 1\n",
            "Frequency of concern is : 1\n",
            "Frequency of jug is : 1\n",
            "Frequency of 1857 is : 1\n",
            "Frequency of mention is : 4\n",
            "Frequency of ree is : 1\n",
            "Frequency of coat is : 1\n",
            "Frequency of 65 is : 1\n",
            "Frequency of 256 is : 1\n",
            "Frequency of 258 is : 1\n",
            "Frequency of three is : 1\n",
            "Frequency of stocah is : 1\n",
            "Frequency of wm is : 1\n",
            "Frequency of l is : 2\n",
            "Frequency of whilock is : 1\n",
            "Frequency of 1880 is : 1\n",
            "Frequency of edward is : 1\n",
            "Frequency of thompson is : 1\n",
            "Frequency of 913 is : 1\n",
            "Frequency of 914 is : 1\n",
            "Frequency of ten is : 1\n",
            "Frequency of weakli is : 1\n",
            "Frequency of 1887 is : 1\n",
            "Frequency of seizur is : 2\n",
            "Frequency of 103 is : 1\n",
            "Frequency of 464 is : 1\n",
            "Frequency of rais is : 2\n",
            "Frequency of annual is : 1\n",
            "Frequency of 1936 is : 1\n",
            "Frequency of all is : 1\n",
            "Frequency of tabl is : 1\n",
            "Frequency of quot is : 1\n",
            "Frequency of page is : 1\n",
            "Frequency of number is : 1\n",
            "Frequency of y is : 2\n",
            "Frequency of sup is : 2\n",
            "Frequency of 1828 is : 1\n",
            "Frequency of admiss is : 1\n",
            "Frequency of contradict is : 1\n",
            "Frequency of substanti is : 1\n",
            "Frequency of vari is : 1\n",
            "Frequency of quitclaim is : 1\n",
            "Frequency of land is : 1\n",
            "Frequency of reserv is : 1\n",
            "Frequency of port is : 1\n",
            "Frequency of 1837 is : 1\n",
            "Frequency of tuskaloosa is : 1\n",
            "Frequency of 108 is : 1\n",
            "Frequency of 1812 is : 1\n",
            "Frequency of let is : 1\n",
            "Frequency of farm is : 2\n",
            "Frequency of six is : 1\n",
            "Frequency of agre is : 1\n",
            "Frequency of render is : 1\n",
            "Frequency of yield is : 1\n",
            "Frequency of half is : 1\n",
            "Frequency of rye is : 1\n",
            "Frequency of grain is : 1\n",
            "Frequency of file is : 2\n",
            "Frequency of neg is : 2\n",
            "Frequency of histori is : 2\n",
            "top 10 1-gram are as follows[(('execut',), 35), (('crop',), 34), (('levi',), 29), (('case',), 23), (('v',), 22), (('court',), 19), (('lien',), 18), (('right',), 18), (('law',), 16), (('rep',), 16)]\n",
            "top 10 2-gram are as follows:[(('grow', 'crop'), 10), (('circuit', 'court'), 9), (('defend', 'execut'), 8), (('case', '—'), 8), (('crop', 'gather'), 7), (('common', 'law'), 7), (('john', 'rep'), 6), (('levi', 'execut'), 6), (('tri', 'hon'), 6), (('plant', 'crop'), 5)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBiC4E_kefvV",
        "colab_type": "text"
      },
      "source": [
        "# 2. Python Regular Expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1QJ-UwCenvN",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Write a Python program to remove leading zeros from an IP address. \n",
        "\n",
        "ip = \"260.08.094.109\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSv6fVhOfFmv",
        "colab_type": "code",
        "outputId": "bede0600-bac9-4258-9f55-487f5bd9eb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import re\n",
        "regex = '\\.[0]*'\n",
        "def Leading_Removed_Zeros(ip):\n",
        "\n",
        "    Removed_Zeros = re.sub(regex, '.', ip)\n",
        "\n",
        "    print(Removed_Zeros)\n",
        "if __name__ == '__main__' : \n",
        "\n",
        " ip = input('Enter the ip address:')\n",
        "Leading_Removed_Zeros(ip)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the ip address:260.08.094.109\n",
            "260.8.94.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXRjaHzrfKAy",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Write a Python Program to extract all the years from the following sentence.\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdJpDx9gjbX",
        "colab_type": "code",
        "outputId": "5054dd94-553d-4517-b93b-6fb0f3732a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Write your code here\n",
        "import re\n",
        "\n",
        "Sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\"\n",
        "data = re.findall(r\"[\\d]{4}\", Sentence)\n",
        "#print(data)\n",
        "print(' Extracted Years')\n",
        "for result in data: \n",
        " if ((eval(result))% 1000 != 0):\n",
        "   print(\"    \" ,result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Extracted Years\n",
            "     2010\n",
            "     2010\n",
            "     2019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}